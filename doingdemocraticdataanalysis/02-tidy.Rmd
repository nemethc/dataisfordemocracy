# Tidy Data

## Cleaning vs Tidying

My wife gives me a hard time because I hate cleaning, but love tidying. Similar things could be said about my mentality when it comes to data cleaning versus data tidying. Unfortunately, as in with life, one must clean before one tidies. But let's start with some conceptual definitions. 

Cleaning refers to the process of scrubbing the data into a way that makes sense to you, the analyst. Oftentimes, and especially in public sector organizations, the data is not clean. Whether you are looking at the output of a SurveyMonkey survey or a canned report that is run from the IT department, your data will come in all shapes and sizes. 

Here is the first major departure from what you may have been taught about data analysis in Excel. When you get messy data *do not* change individual cell values (if you can at all help it). Recall from the introductory chapter the difference between cells and fields. Fields, as a reminder, are columns that represent one variable. Whenever possible, use data analysis tools to make changes to the entire field, rather than specific cells. Most data analysis software, outside of Excel, make it difficult or impossible to change individual cell values. This is important for several reasons, most of which we will get to in the next chapter on reproducibility. But for now, thinking in terms of fields, and making changes to entire fields, will save you *a lot* of work and  headache in the long run. Let's look at a sample dataset that may be similar to one you would encounter in real life. Here is a survey collected by a field manager of a local parks and recreation department on employment. 

```{r libs, include=FALSE}
library(DT)

```


```{r dirty-data, message=FALSE, warning=FALSE, echo=TRUE}
library(tidyverse)

sites <- tribble(
  ~"Employee", ~"Location", ~"Telecommute?", ~"Hire Date",
  "ron swanson", "Pawnee City Hall", "never", "Unknown",
  "Knope, Leslie", "Field Duty", "1 day/week", "2011-6-1",
  "Andy Dwyer", "sullivan street pit", "40 hours", "March 1, 2013",
  "Jerry Gergich", "City Hall", "never", "6/1/1985",
  "Garry Gergich", "City Hall", "never", "6/1/1985",
  "ben wyatt", "Partridge, Minnesota","" , "Jan. 1, 2010"
)

sites %>% datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = 'excel',
                   searching = FALSE))
```

In this example, it would be trivial to go in to the Excel file and clean up the dates, names, and locations by hand. However, you could imagine this survey replicated for a department of forty employees. It quickly becomes unfeasable to make those edits by hand. When this is the case, there are functions in Excel and R that will make your life much easier. 

Here is annotated code for how I would go about cleaning this table in R. The friendly syntax of the `tidyverse` packages makes it easy to follow along, even if you aren't comfortable writing it yourself. 

```{r}
sites_cleaned <- sites %>% #creating a new table called "sites_cleaned", starting with the old table "sites"
  mutate(Employee = if_else(Employee == "Knope, Leslie", "Leslie Knope", Employee)) %>% 
  separate(Employee, into = c("first_name", "last_name")) %>% 
  rename(location = Location,
         telecommute_hours =`Telecommute?`,
         hire_date = `Hire Date`) %>% 
  mutate(first_name = str_to_title(first_name),
         last_name = str_to_title(last_name),
         location = str_to_title(location)) %>% 
  mutate(location = case_when(
           str_detect(location, "City Hall") ~ "In Office",
           str_detect(location, "Field") ~ "In Field",
           str_detect(location, "Street") ~ "In Field",
           TRUE ~ "Other"),
         telecommute_hours = case_when(
           telecommute_hours == "never" ~ 0,
           telecommute_hours == "1 day/week" ~ 8,
           telecommute_hours == "40 hours" ~ 40
         )
         )
  
  
```


## Thinking in Pivot Tables-- From Wide to Long. 

Pivot tables are amazing. THey are the world's most common, most helpful, and most underrated data analysis tool. PowerBI interactive charts and graphs are just pivot tables in disguise. Understanding what is needed to make a pivot table work is the key to the wide world of data analysis. 

A pivot table groups data by field and allows the user to drag fields to the rows or columns of the pivot table. This is effective when each field is a variable (something that can change), and each row is a seperate observation of some phenomena of interest. 

In short, pivot tables depend on **tidy data**. 

Tidy data is the way your data should be organized before you begin your analysis. In tidy data, each column is a *variable*, each row is an *observation*, and each table is an *associated set of observations*. What does that mean in practice? Consider the following example. 

Below is a table^[Data was created for demonstration purposes] that shows types of retirement visits for a month at a state's Department of Retirement Services by the employee who took the visit and the visit type. 
  
```{r tables-visits, message=FALSE, warning = FALSE, echo=TRUE}
visits <- tribble(
  ~"Employee", ~"Phone Visits", ~"Office Visits", ~"Online Visits",
  "Danielle", 6, 11, 23,
  "Ramona", 11, 5, 18,
  "Ross", 10, 10, 10 
)

knitr::kable(visits, caption = "Visits to the Dept. of Retirement Services in a given month")

```
  
Data are frequently displayed in this "wide" format. It works great for presentation, but not great for data analysis. 

The shortcomings of data in this format may become apparent when you attempt to work with the data in a pivot table. This is becuase our columns aren't truly variables. You can drag the fields from the top row to the grey box below, for columns, and the left, for rows. This becomes unmanegable quickly. 

```{r}
rpivotTable::rpivotTable(visits, width = "60%", height = "60%")
```





Let's apply our criteria of tidy data to this set:

* Variables
    * At first glance, it doensn't look like this is a problem. But think again. Is `phone visits` really a variable? Or is the real variable of interest number of visits? And are our column names actually variables too (type of visit)? 
    
Let's take another swing at setting up our table for data analysis purposes. This can be accomplished easily in R using the code below, or in Excel by loading the data with `Get and Transform` -> selecting the three "visits" columns -> right clicking -> and selecting "unpivot columns."

```{r}
#We have already loaded the "tidyverse" library so we do not have to do it again

pivot_visits <- visits %>% #we are editing the "visits" table already created by storing it in a new table pivot_visits
  pivot_longer(-Employee, names_to = "Visit Type", values_to = "Number of Visits") #using pivot_longer on every column except "employee" and setting the name of the new columns


knitr::kable(pivot_visits, caption = "Visits to the Dept. of Retirement Services in a given month")
```

Now this is a table that is much easier to analyze in an Excel pivot table or with a variety of R functions. Using data in this format, it is easy to recreate the original table for presentation, while also giving a variety of options for formatting and plotting. Use the pivot table below to recreate the original table using the tidy data. *Hint- Instead of Count, select Sum -> Number of Visits as the value field. It is far easier to work with fields when they are in a tidy format. 


```{r}
rpivotTable::rpivotTable(pivot_visits, width = "60%", height = "400px")
```


When we get to the next chapter, you will learn several alternatives to pivot tables that use the same principles, but are more reproducible. 

## Using lower level data

Let's introduce a slightly more complicated tidy data problem, using the same base data as before. 

```{r}
visits_retirements <- tribble(
  ~"Employee", ~"Phone Visits", ~"Phone Retirements", ~"Office Visits", ~"Office Retirements", ~"Online Visits", ~"Online Retirements",
  "Danielle", 6, 4, 11, 8, 23, 15,
  "Ramona", 11, 7, 5, 3, 18, 15,
  "Ross", 10, 8, 10, 7, 10, 9 
)

knitr::kable(visits_retirements, caption = "Visits to the Dept. of Retirement Services in a given month by employee and associated client retirements")
```

Hopefully you will see a similar pattern here. Now, there are three variables: Visit type, number of visits, and number of retirements. Again, this data works fine for presentation but could use tidying to ease in analysis. 

```{r}
visits_retirements %>%
  DT::datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = 'excel',
                   searching = FALSE))
```

Try to tidy this in R or Excel Get and Transform. See this footnote^[powerquery hints] or look at the code if you need a hint. 


```{r}
visits_retirements_tidy <- visits_retirements %>%
  pivot_longer(cols = -Employee, 
               names_to = c("Visit Location", "Type"), 
               names_sep = " ")

print(visits_retirements_tidy)
```
In this case, we actually pivoted too far. It will probably be more useful to have the counts of visits and retirements in their own category. Keep in mind the scope of the observation-- It is perfectly valid for each to have their own column, as it is visits and retirements per month. 

```{r}
visits_retirements_tidy2 <- visits_retirements_tidy %>% 
  pivot_wider(id_cols = c(Employee, `Visit Location`, Type), names_from = Type, values_from = value)

print(visits_retirements_tidy2)
```

From here, it is easy to do calculations based on fields, rather than cells. For example, in R or Get and Transform, you could add the following:

```{r}
visits_pct <- visits_retirements_tidy2 %>% 
  mutate(pct_retirements = Retirements / Visits)

print(visits_pct)
```


And then, one of the most useful things you can do is develop formulas by grouping of rows. For example, you may want to know the total number of visits and retirements by retiree, regardless of visit location. That can be accomplished in a pivot table. 

```{r}

```


## So how is this democratic?


## Practice problems

  